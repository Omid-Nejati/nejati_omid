<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  </script>

  <title>Omid Nejati Manzari</title>
  
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
    <link rel="icon" type="png" href="Doc/icon.png">

</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:6%;width:63%;text-align: justify">
              <p style="text-align:center">
                <name>Omid Nejati Manzari</name>
              </p>
			  <p>I am a research assistant at the Computer Vision Center at the Iran University of Science & Technology. I started  master in Electrical Engineering in 2018, under supervised by Prof. <a href="https://scholar.google.ca/citations?hl=en&user=sMPEoRcAAAAJ&view_op=list_works&sortby=pubdate">Shahriar Baradaran Shokouhi</a>. My long-term research goal is to enable AI agents to explain phenomena beyond low-level statistics of observable data.
              </p>

              </p>
              <p style="text-align:center">

				<a href="mailto:omid.nejati@gmail.com">Email</a> &nbsp/&nbsp
                <!--<a href="Doc/homepage_cv.pdf">CV</a> &nbsp/&nbsp-->
                <a href="https://www.linkedin.com/in/omid-nejati-manzari-a22515119/">LinkedIn</a> &nbsp/&nbsp
     		<a href="https://github.com/Omid-Nejati">Github</a>
              </p>
            </td>
            <td style="padding:2.5%;width:40%;max-width:40%">
			  <img width=100% src="Doc/profile_pic.jpg">

            </td>
           </tr>
</p>
        </tbody></table>
        <table style="width:100%"><tbody>
            <tr>
            <td style="width:100%">
              <heading>Publications</heading>
            </td>
          </tr>
        </tbody></table>
        <table style="width:120%"><tbody>

          <tr onmouseout="nightsight_stop()" onmouseover="nightsight_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='nightsight_image'><img src='Doc/iccke1.png'></div>
                <img src='Doc/iccke2.png'>

              </div>
              <script type="text/javascript">
                function nightsight_start() {
                  document.getElementById('nightsight_image').style.opacity = "1";
                }
                function nightsight_stop() {
                  document.getElementById('nightsight_image').style.opacity = "0";
                }
                nightsight_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle;text-align: justify">
                <papertitle> A Robust Network for Embedded Traffic Sign Recognition.</papertitle>
              </a>
              <br>
              <strong>Omid Nejati Manzari</strong>,
			  <a href="https://scholar.google.ca/citations?hl=en&user=sMPEoRcAAAAJ&view_op=list_works&sortby=pubdate">Shahriar B Shokouhi</a>
              <br>
			  <em>International Conference on Computer and Knowledge Engineering </em>, 2021

              <p>In This paper proposes a network that uses
			residual blocks in the network to obtain a top-1 accuracy of 99.51
			for the German traffic sign recognition benchmark. The number
			of parameters is ∼430,000, which is ∼32x fewer than the state-ofthe-art. Experiments have been performed to show the network's
			resistance to destructive factors and its comprehensiveness in the
			application of traffic sign recognition. These tests show that it is a
			comprehensive and robust network for the recognition of traffic
			signs.</p>
            </td>
          </tr>
          
          <tr onmouseout="font_stop()" onmouseover="font_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='font_image'><img src='Doc/ICCKE_2.png'></div>
                <img src='Doc/ICCKE.png'>
              </div>
              <script type="text/javascript">
                function font_start() {
                  document.getElementById('font_image').style.opacity = "1";
                }
                function font_stop() {
                  document.getElementById('font_image').style.opacity = "0";
                }
                font_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle;text-align: justify">
                <papertitle>Patchwise object tracking via structural local sparse appearance model.</papertitle>
              </a>
              <br>
              <strong>Hossein Kashiani</strong>,
			  <a href="https://scholar.google.ca/citations?hl=en&user=sMPEoRcAAAAJ&view_op=list_works&sortby=pubdate">Shahriar B Shokouhi</a>
              <br>
			  <em>International Conference on Computer and Knowledge Engineering </em>, 2017

              <p>In this paper, we propose a robust visual tracking method which exploits the relationships of targets
			  in adjacent frames using patchwise joint sparse representation. Two sets of overlapping patches with different
			  sizes are extracted from target candidates to construct two dictionaries with consideration of joint sparse representation.
			  By applying this representation into structural sparse appearance model, we can take two-fold advantages.
			  First, correlation of target patches is considered over time. Second, using this local appearance model with different
			  patch sizes takes into account local features of target thoroughly. Furthermore, the position of candidate patches and
			  their occlusion levels are utilized simultaneously to obtain the final likelihood of target candidates.</p>
            </td>
          </tr>
         </tr>
       </tbody></table>
        <table style="width:100%"><tbody>
            <tr>
            <td style="width:100%;">
              <heading>Preprints</heading>
            </td>
          </tr>
        </tbody></table>
        <table style="width:120%;margin-left:auto"><tbody>

          <tr onmouseout="nightsight_stop_()" onmouseover="nightsight_start_()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='nightsight_image_'><img src='Doc/2.png'></div>
                <img src='Doc/1.png'>

              </div>
              <script type="text/javascript">
                function nightsight_start_() {
                  document.getElementById('nightsight_image_').style.opacity = "1";
                }
                function nightsight_stop_() {
                  document.getElementById('nightsight_image_').style.opacity = "0";
                }
                nightsight_stop_()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle;text-align: justify">

                <papertitle> Online Visual Tracking with One-Shot Context-Aware Domain Adaptation.</papertitle>
			  <br>
              <strong>Hossein Kashiani</strong>,
			   Amir Abbas H. Imani,
			  <a href="https://scholar.google.ca/citations?hl=en&user=sMPEoRcAAAAJ&view_op=list_works&sortby=pubdate">Shahriar B. Shokouhi</a>,
			  <a href="https://scholar.google.nl/citations?user=KjumZJgAAAAJ&hl=en&authuser=1">Ahmad Ayatollahi</a>

              <p> Online learning policy makes visual trackers more robust against different
				distortions through learning domain-specific cues. However, the trackers adopting this policy fail to fully leverage the discriminative context of the background
				areas. Moreover, owing to the lack of sufficient data at each time step, the online learning approach can also make the trackers prone to over-fitting to the
				background regions. In this paper, we propose a domain adaptation approach to
				strengthen the contributions of the semantic background context. The domain
				adaptation approach is backboned with only an off-the-shelf deep model. The
				strength of the proposed approach comes from its discriminative ability to handle severe occlusion and background clutter challenges.</p>
            </td>
          </tr>	  
	</tbody></table>
        <table style="width:100%;"><tbody>
            <tr>
            <td style="width:100%;">
              <heading>Projects</heading>
			  <br><br><br><br><br>
			  </a>
            </td>
          </tr>
        </tbody></table>
        <table style="width:120%"><tbody>

         <tr onmouseout="nightsight_stop_2()" onmouseover="nightsight_start_2()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='nightsight_image_2'><img src='Doc/Generalizing.png'></div>
                <img src='Doc/Generalizing.png'>
              <script type="text/javascript">
                function nightsight_start_2() {
                  document.getElementById('nightsight_image_2').style.opacity = "1";
                }
                function nightsight_stop_2() {
                  document.getElementById('nightsight_image_2').style.opacity = "0";
                }
                nightsight_stop_2()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle;text-align: justify">
                <papertitle> Generalizing State-of-the-art Object Detectors for Autonomous Vehicles in Unseen Environments.</papertitle>
              </a>


              <p> The ability to detect various objects in an unseen environment is a crucial yet
				tricky task for autonomous vehicles (AVs). Despite the significant improvements in recent years, researchers have yet to achieve an accurate perception
				of an unknown environment. In this respect, data-driven models are one of the bottlenecks for researches to enjoy advances in the object detection field.
				That is to say, due to the distribution mismatch, models trained on the available datasets fail to generalize well to the complex, real-world scenarios with
				higher dynamics. In this work, we investigate the generalization of one- and two-stage object detectors to our previously unseen dataset and attempt to handle the mentioned bottleneck. </p>
            </td>
			
         </tr>

		<table width="100%">
		<tr><td>
			<heading>Teaching Assistant</heading>
			<ul>
			<li> Computer Vision, Spring 2021</li>
			<li> Machine Learning, Fall 2020</li>
			<li> Computer Vision, Fall 2018</li>
			<li> Intelligent Systems, Fall 2017</li>
			</ul>
		  </td></tr>
        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
        <tbody><tr>
        <td>
        <br>
        <p align="right">
          <font size="2">
		      Time saved by <a href="https://jonbarron.info//">this</a> awesome website.
	    </font>
        </p>
        </td>
        </tr>
		
      </td>
    </tr>
  </table>
</body>

</html>
