<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  </script>

  <title>Omid Nejati Manzari</title>
  
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
    <link rel="icon" type="png" href="Doc/icon.png">

</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:6%;width:63%;text-align: justify">
              <p style="text-align:center">
                <name>Omid Nejati Manzari</name>
              </p>
			  <p>I am a research assistant at the Computer Vision Center at the Iran University of Science & Technology.
				  I started  master in Electrical Engineering in 2018,  which is being conducted under the supervision
				  of Prof. <a href="https://scholar.google.ca/citations?hl=en&user=sMPEoRcAAAAJ&view_op=list_works&sortby=pubdate">Shahriar 
				  Baradaran Shokouhi</a>. My long-term research goal is to enable AI agents to explain phenomena beyond low-level statistics
				  of observable data.
              </p>

              </p>
              <p style="text-align:center">

				<a href="mailto:omid.nejati@gmail.com">Email</a> &nbsp/&nbsp
                <!--<a href="Doc/homepage_cv.pdf">CV</a> &nbsp/&nbsp-->
                <a href="https://www.linkedin.com/in/omid-nejati-manzari-a22515119/">LinkedIn</a> &nbsp/&nbsp
     		<a href="https://github.com/Omid-Nejati">Github</a>
              </p>
            </td>
            <td style="padding:2.5%;width:40%;max-width:40%">
			  <img width=100% src="Doc/profile_pic.jpg">

            </td>
           </tr>
</p>
        </tbody></table>
        <table style="width:100%"><tbody>
            <tr>
            <td style="width:100%">
              <heading>Publications</heading>
            </td>
          </tr>
        </tbody></table>
        <table style="width:120%;margin-left:auto"><tbody>

          <tr onmouseout="nightsight_stop_()" onmouseover="nightsight_start_()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='nightsight_image_'><img src='Doc/iccke2.png'></div>
                <img src=''>

              </div>
              <script type="text/javascript">
                function nightsight_start_() {
                  document.getElementById('nightsight_image_').style.opacity = "1";
                }
                function nightsight_stop_() {
                  document.getElementById('nightsight_image_').style.opacity = "0";
                }
                nightsight_stop_()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle;text-align: justify">
                <papertitle> A Robust Network for Embedded Traffic Sign Recognition.</papertitle>
              </a>
              <br>
              <strong>Omid Nejati Manzari</strong>,
			  <a href="https://scholar.google.ca/citations?hl=en&user=sMPEoRcAAAAJ&view_op=list_works&sortby=pubdate">Shahriar B Shokouhi</a>
              <br>
			  <em>International Conference on Computer and Knowledge Engineering </em>, 2021

              <p>In This paper proposes a network that uses
			residual blocks in the network to obtain a top-1 accuracy of 99.51
			for the German traffic sign recognition benchmark. The number
			of parameters is ∼430,000, which is ∼32x fewer than the state-ofthe-art. Experiments have been performed to show the network's
			resistance to destructive factors and its comprehensiveness in the
			application of traffic sign recognition. These tests show that it is a
			comprehensive and robust network for the recognition of traffic
			signs.</p>
            </td>
          </tr>
          
          
         </tr>
       </tbody></table>
        <table style="width:100%"><tbody>
            <tr>
            <td style="width:100%;">
		    	<br><br>
              <heading>Preprints</heading>
		    	    <br><br><br>
			  </a>
            </td>
          </tr>
        </tbody></table>
        <table style="width:120%;margin-left:auto"><tbody>

          <tr onmouseout="nightsight_stop_()" onmouseover="nightsight_start_()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='nightsight_image_'><img src='Doc/letter.png'></div>
                <img src='Doc/letter.png'>

              </div>
              <script type="text/javascript">
                function nightsight_start_() {
                  document.getElementById('nightsight_image_').style.opacity = "1";
                }
                function nightsight_stop_() {
                  document.getElementById('nightsight_image_').style.opacity = "0";
                }
                nightsight_stop_()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle;text-align: justify">

                <papertitle> Robust Transformer with Locality Inductive Bias and Feature Normalization.</papertitle>
			  <br>
              <strong>Omid Nejati Manzari</strong>,
			   Hossein Kashiani,
			  <a href="https://scholar.google.ca/citations?hl=en&user=sMPEoRcAAAAJ&view_op=list_works&sortby=pubdate">Shahriar B. Shokouhi</a>

              <p>In this paper, we explore
					the robustness of vision transformers against adversarial
					perturbations and try to enhance their robustness/accuracy
					trade-off in white box attack settings. To this end, we
					propose Locality iN Locality (LNL) transformer model. We
					prove that the locality introduction to LNL contributes to
					the robustness performance since it aggregates local
					information such as lines, edges, shapes, and even objects.
					In addition, to further improve the robustness performance.</p>
            </td>
          </tr>	  
	</tbody></table>
        <table style="width:100%;"><tbody>
            <tr>
            <td style="width:100%;">
              <heading>Projects</heading>
			  <br><br><br><br><br>
			  </a>
            </td>
          </tr>
        </tbody></table>
        <table style="width:120%"><tbody>

         <tr onmouseout="nightsight_stop_2()" onmouseover="nightsight_start_2()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='nightsight_image_2'><img src='Doc/covid.png'></div>
                <img src='Doc/covid.png'>
              <script type="text/javascript">
                function nightsight_start_2() {
                  document.getElementById('nightsight_image_2').style.opacity = "1";
                }
                function nightsight_stop_2() {
                  document.getElementById('nightsight_image_2').style.opacity = "0";
                }
                nightsight_stop_2()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle;text-align: justify">
                <papertitle>Local Transformer for COVID-19 Detection Using Chest CT Scans.</papertitle>
              </a>


              <p>Convolutional Neural Networks (CNNs) have mainly
								failed to explicitly model long-range dependencies, primarily
								because of their intrinsic locality. To address this issue, Transformers have drawn increasing interest in exploiting long-range
								dependencies among input data. In this study, we aim to enjoy
								the merits of both local and global feature extractions in CNN
								and Transformer architectures. To this end, we go beyond the
								conventional Transformer frameworks and introduce a highly
								efficient Transformer architecture for early diagnosis and treatment of COVID-19 patients using CT images </p>
            </td>		
         </tr>

	<tr onmouseout="nightsight_stop_()" onmouseover="nightsight_start_()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='nightsight_image_'><img src='Doc/line_det.gif'></div>
                <img src=''>

              </div>
              <script type="text/javascript">
                function nightsight_start_() {
                  document.getElementById('nightsight_image_').style.opacity = "1";
                }
                function nightsight_stop_() {
                  document.getElementById('nightsight_image_').style.opacity = "0";
                }
                nightsight_stop_()
              </script>
              <br>
		    
              <td style="padding:20px;width:75%;vertical-align:middle;text-align: justify">
                <papertitle>Fast Drivable Area for Autonomous Driving with Line Detection and Deep Neural Network.</papertitle>
              </a>

              <p>In Autonomous cars use images of the road to detect drivable areas,
		     			 identify lanes, objects near the car, and necessary information.
		     			 This information achieved from the road images are used  to  make
		     			 suitable  driving  decisions  for  self-driving  cars. Drivable 
		      			 area detection is a technique that segments the drivable parts of
		      			 roads in the image. Modern methods often consider road detection as
		      			 a pixel by pixel classification task, which is struggling to  solve  the
		      			 problem  of  computational  cost  and  speed.  So  to increase the speed 
		      			 of  performance, we consider the  process of drivable area recognition as
		      			 a row-selection task. In this paper, special rows in the image are selected.
		      			 Then, the boundaries of the drivable area are detected in these rows.</p>
            </td>
          </tr>

		<table width="100%">
		<tr><td>
			<heading>Researh Interest</heading>
			<ul>
			<li> Computer Vision</li>
			<li> Machine Learning</li>
			<li> Medical Image Processing</li>
			</ul>
		  </td></tr>
        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
        <tbody><tr>
        <td>
        <br>
        <p align="right">
          <font size="2">
		      Time saved by <a href="https://jonbarron.info//">this</a> awesome website.
	    </font>
        </p>
        </td>
        </tr>
		
      </td>
    </tr>
  </table>
</body>

</html>
